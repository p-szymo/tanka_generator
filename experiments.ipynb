{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pronouncing import phones_for_word, syllable_count\n",
    "from collections import defaultdict\n",
    "from functions import *\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import wordninja\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciation_list = phones_for_word(\"programming\")\n",
    "syllable_count(pronunciation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P R OW1 G R AE2 M IH0 NG']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pronunciation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_count(phones_for_word(\"enumerate\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where shall we go for our garlands glad \\n at the falling of the year \\n when the burntup banks are ye'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.expanduser(\"~/Documents/python_poetry/poetrydb_poem_generator/\")\n",
    "f = open(file_path + \"poems_raw.txt\", \"r\")\n",
    "poems_raw = f.read()\n",
    "poems_raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'burnt', 'up', 'banks', 'are']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_segmented = wordninja.split(poems_raw)\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where', 'shall', 'we', 'go', 'for', 'our', 'garlands', 'glad', 'at', 'the']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_segmented[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'maries' in poems_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_known_words = [word for word in poems_segmented if phones_for_word(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'maries' in poems_known_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['must', 'and', 'shows', 'where', 'while']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_dictionary = defaultdict(list)\n",
    "\n",
    "for current_word, next_word in zip(poems_known_words, poems_known_words[1:]):\n",
    "    poems_dictionary[current_word].append(next_word)\n",
    "\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'maries' in poems_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tankanizer(po_dict):\n",
    "\n",
    "    tanka = []\n",
    "    line_1 = []\n",
    "    line_2 = []\n",
    "    line_3 = []\n",
    "    line_4 = []\n",
    "    line_5 = []\n",
    "    \n",
    "    syllables = 0\n",
    "    while syllables == 0:\n",
    "        first_word = random.choice(list(po_dict.keys()))\n",
    "        syl_count = syllable_count(phones_for_word(first_word)[0])\n",
    "        if syl_count <= 5:\n",
    "            line_1.append(first_word)\n",
    "            syllables += syl_count\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    while syllables < 5:\n",
    "        next_word = random.choice(po_dict[line_1[-1]])\n",
    "        syl_count = syllable_count(phones_for_word(next_word)[0])\n",
    "        if syl_count <= (5 - syllables):\n",
    "            line_1.append(next_word)\n",
    "            syllables += syl_count\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    print((' ').join(line_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.expanduser(\"~/Documents/python_poetry/custom_corpus_streams/writings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'world',\n",
       " 'knew',\n",
       " 'it',\n",
       " 'was',\n",
       " 'december',\n",
       " 'my',\n",
       " 'fucking',\n",
       " 'chest',\n",
       " 'is',\n",
       " 'caving',\n",
       " 'in',\n",
       " 'teeth',\n",
       " 'all',\n",
       " 'grimy',\n",
       " 'and',\n",
       " 'shit',\n",
       " 'seventeen',\n",
       " 'graffitto',\n",
       " \"ain't\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_path = os.path.expanduser(\"~/Documents/python_poetry/custom_corpus_streams/writings\")\n",
    "\n",
    "corpus = PlaintextCorpusReader(writings_path, '.*', word_tokenizer=RegexpTokenizer(pattern=\"([a-zA-Z]+(?:'[a-z]+)?)\"))\n",
    "\n",
    "corpus.words()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'world',\n",
       " 'knew',\n",
       " 'it',\n",
       " 'was',\n",
       " 'december',\n",
       " 'my',\n",
       " 'fucking',\n",
       " 'chest',\n",
       " 'is',\n",
       " 'caving',\n",
       " 'in',\n",
       " 'teeth',\n",
       " 'all',\n",
       " 'grimy',\n",
       " 'and',\n",
       " 'shit',\n",
       " 'seventeen',\n",
       " \"ain't\",\n",
       " 'got']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word.lower() for word in corpus.words() if phones_for_word(word)]\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in words:\n",
    "    if len(word) != 1:\n",
    "        words.append(word)\n",
    "    else:\n",
    "        if word in ['a', 'e', 'i', 'o', 'u', 'x', 'y', 'z']:\n",
    "            words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world', 'mark', 'willows', 'twain', 'house']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dictionary = defaultdict(list)\n",
    "\n",
    "for current_word, next_word in zip(words, words[1:]):\n",
    "    words_dictionary[current_word].append(next_word)\n",
    "\n",
    "words_dictionary['the'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advantage with it\n",
      "my eyes like a little more\n",
      "than two eccentrics\n",
      "you oh yeah and just an odd\n",
      "desire line i bet it\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "obligated much\n",
      "outright and stepped inside their\n",
      "lights it s a bay\n",
      "tree plucked up to stop her eyes\n",
      "stopped it across the words oh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "leaving the world please\n",
      "i tell me they expression\n",
      "murder three total\n",
      "darkness save a while she turned\n",
      "island of hell out of life\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "surfaces of the\n",
      "clouds entangling the deal my\n",
      "way one dish to you\n",
      "meet the sky grey lights grow blind\n",
      "man to compare of my time\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-f8b95396a5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtankanizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-e4db4826c542>\u001b[0m in \u001b[0;36mtankanizer\u001b[0;34m(word_dict, start_word)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mline_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mline_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mline_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtanka\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-4a9939a6f9b2>\u001b[0m in \u001b[0;36mline_creator\u001b[0;34m(word_dict, num_syllables, prompt)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_syllables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtemp_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyllable_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphones_for_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemp_count\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnum_syllables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    tankanizer(words_dictionary)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = []\n",
    "count = 0\n",
    "while count == 0:\n",
    "    start_word = random.choice(list(words_dictionary.keys()))\n",
    "    count = syllable_count(phones_for_word(start_word)[0])\n",
    "    if count <= 5:\n",
    "        line.append(start_word)\n",
    "    else:\n",
    "        count = 0\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sprout']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trains'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'tossed']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dictionary[start_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_creator(word_dict, num_syllables, prompt=None):\n",
    "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
    "       along with the number of words you would like to see in your generated sentence.'''\n",
    "    \n",
    "    line = []\n",
    "    count = 0\n",
    "    \n",
    "    if prompt:\n",
    "        while count == 0:\n",
    "            start_word = random.choice(word_dict[prompt])\n",
    "            count = syllable_count(phones_for_word(start_word)[0])\n",
    "            if count <= num_syllables:\n",
    "                line.append(start_word)\n",
    "            else:\n",
    "                count = 0\n",
    "                continue\n",
    "    else:\n",
    "        while count == 0:\n",
    "            start_word = random.choice(list(word_dict.keys()))\n",
    "            count = syllable_count(phones_for_word(start_word)[0])\n",
    "            if count <= num_syllables:\n",
    "                line.append(start_word)\n",
    "            else:\n",
    "                count = 0\n",
    "                continue\n",
    "\n",
    "    while count < num_syllables:\n",
    "        next_word = random.choice(word_dict[line[-1]])\n",
    "        temp_count = count + syllable_count(phones_for_word(next_word)[0])\n",
    "        if temp_count <= num_syllables:\n",
    "            line.append(next_word)\n",
    "            count += syllable_count(phones_for_word(next_word)[0])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tankanizer(word_dict, start_word=None):\n",
    "\n",
    "    line_1 = line_creator(word_dict, 5, start_word)\n",
    "    line_2 = line_creator(word_dict, 7, line_1[-1])\n",
    "    line_3 = line_creator(word_dict, 5, line_2[-1])\n",
    "    line_4 = line_creator(word_dict, 7, line_3[-1])\n",
    "    line_5 = line_creator(word_dict, 7, line_4[-1])\n",
    "    lines = [line_1, line_2, line_3, line_4, line_5]\n",
    "    tanka = [(' ').join(line) for line in lines]\n",
    "    \n",
    "    print(('\\n').join(tanka))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['downing', 'a', 'program']\n",
      "['identifying']\n",
      "['sly', 'for', 'a', 'i', 'should']\n",
      "['consciousness', 'for', 'all']\n",
      "['triggers', 'Three', 'Scene', 'As']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(line_creator(words_dictionary, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holds firmly stroking\n",
      "it may argue with clean tooth\n",
      "on me me away\n",
      "And puncture him Let there may\n",
      "be degrees Listen Two girls\n"
     ]
    }
   ],
   "source": [
    "tankanizer(words_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
